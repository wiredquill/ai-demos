# AI Demos Collection

**Comprehensive enterprise AI demonstrations showcasing SUSE's complete cloud-native AI platform**

This repository provides end-to-end demonstrations of AI application deployment, security, observability, and management using SUSE's enterprise-grade cloud-native stack. Perfect for sales demonstrations, technical evaluations, and hands-on learning.

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Repository Overview](#-repository-overview)
- [ğŸš€ AI Compare Application](#-ai-compare-application)
- [ğŸ“– Available Demonstrations](#-available-demonstrations)
- [ğŸ› ï¸ Quick Start](#ï¸-quick-start)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸ”§ Advanced Configuration](#-advanced-configuration)
- [ğŸ¤ Contributing](#-contributing)

---

## ğŸ¯ Repository Overview

This repository contains a complete collection of AI demonstration materials organized into three main categories:

### **1. ğŸ¤– AI Compare Application**
A production-ready AI response comparison tool that demonstrates:
- **Direct vs Pipeline-Enhanced AI Responses**: Side-by-side comparison of local LLM responses vs processed responses
- **Security Demonstrations**: Built-in NeuVector DLP testing with dual data type transmission
- **Enterprise Integration**: OpenTelemetry observability, GPU acceleration, persistent storage
- **Multi-Deployment Options**: Rancher UI, Helm CLI, GitOps with Fleet

### **2. ğŸ“‹ Platform Demonstrations** 
Guided demonstrations covering:
- **Infrastructure**: GPU provisioning and management with Rancher
- **Deployment**: Multiple deployment methodologies for AI workloads
- **Observability**: AI-specific monitoring with SUSE Observability
- **Security**: Container security and runtime protection with NeuVector
- **Zero-Trust**: Network security and policy enforcement

### **3. ğŸ—ï¸ Enterprise Infrastructure**
Complete deployment automation including:
- **Helm Charts**: Production-ready charts for both upstream and SUSE variants
- **GitOps**: Fleet-based continuous deployment configurations
- **Observability**: Pre-configured monitoring and alerting
- **Security**: NeuVector policy automation and DLP configurations

---

## ğŸš€ AI Compare Application

### **Core Functionality**
The flagship AI Compare application provides real-time comparison between:

- **ğŸ¤– Direct Ollama**: Local LLM inference (TinyLlama, Llama2, custom models)
- **ğŸŒ Pipeline-Enhanced**: Processed responses through Open WebUI pipelines with educational levels:
  - ğŸ‘¶ Kid-friendly explanations
  - ğŸ“ Student-level responses  
  - âš—ï¸ Scientific detailed analysis

### **Built-in Security Demonstrations**

#### **ğŸ”’ Data Leak Prevention (DLP) Demo**
- **Dual Data Transmission**: Single button sends both credit card and SSN data
- **Credit Card**: `3412-1234-1234-2222`
- **Social Security Number**: `123-45-6789`
- **NeuVector Integration**: Triggers real-time DLP monitoring and alerting
- **Clean Interface**: Simple popup showing "âš ï¸ Attempting to send sensitive data"

#### **ğŸŒ Availability Demo**
- **External Connectivity**: Tests connection to https://suse.com
- **Network Policy Validation**: Demonstrates network segmentation capabilities
- **Security Monitoring**: Validates outbound connection policies

### **Enterprise Features**
- **ğŸ“Š Real-time Observability**: OpenTelemetry integration with SUSE Observability
- **ğŸ–¥ï¸ GPU Acceleration**: NVIDIA GPU support with runtime configuration
- **ğŸ’¾ Persistent Storage**: Model caching and configuration persistence
- **ğŸ”„ Automation**: Background testing and response comparison
- **ğŸ‘¥ Provider Monitoring**: Live status of major AI providers (OpenAI, Anthropic, Google, etc.)

---

## ğŸ“– Available Demonstrations

### **Platform Demonstrations (Guided Walkthroughs)**

| Demo | Focus Area | Duration | Key Takeaways |
|------|------------|----------|---------------|
| **[Demo 1: Accelerating AI with Rancher and GPUs](./demo-1.md)** | Infrastructure | 15 min | GPU provisioning, cluster management, hardware optimization |
| **[Demo 2: Deploying the SUSE AI Stack](./demo-2.md)** | Deployment | 20 min | Rancher UI, Helm CLI, GitOps deployment methods |
| **[Demo 3: Monitoring AI with SUSE Observability](./demo-3.md)** | Observability | 15 min | GPU metrics, cost tracking, performance optimization |
| **[Demo 4: Building Trustworthy AI](./demo-4.md)** | Security | 20 min | Container scanning, vulnerability management, policy automation |
| **[Demo 5: Zero-Trust Security for AI](./demo-5.md)** | Network Security | 15 min | Runtime protection, network policies, threat detection |

### **Interactive Application Demos (Built-in)**

| Demo | Trigger | Data Transmitted | NeuVector Detection |
|------|---------|------------------|-------------------|
| **ğŸ”’ Data Leak Demo** | Single Button | Credit Card + SSN | Multi-pattern DLP alerts |
| **ğŸŒ Availability Demo** | Single Button | HTTPS Request | Network policy validation |

---

## ğŸ› ï¸ Quick Start

### **Prerequisites**
- Kubernetes cluster (RKE2 recommended)
- Helm 3.x
- kubectl configured
- Optional: GPU nodes with NVIDIA drivers

### **Deployment Options**

#### **Option 1: Rancher Apps & Marketplace (Recommended)**
1. Open Rancher cluster management interface
2. Navigate to **Apps & Marketplace**
3. Search for "AI Compare"
4. Select variant:
   - `ai-compare-suse`: Enterprise SUSE edition
   - `ai-compare`: Upstream community edition
5. Configure and deploy

#### **Option 2: Helm CLI**
```bash
# SUSE Enterprise Edition
helm install ai-demo charts/ai-compare-suse \
  --set ollama.gpu.enabled=true \
  --set aiCompare.observability.enabled=true

# Upstream Community Edition  
helm install ai-demo charts/ai-compare
```

#### **Option 3: GitOps with Fleet**
```bash
# Deploy Fleet configuration
kubectl apply -f fleet/fleet.yaml

# Label target clusters
kubectl label cluster my-cluster needs-llm-suse=true
```

### **Access the Application**
```bash
# Port forward to access locally
kubectl port-forward svc/ai-demo-app-service 7860:7860

# Open browser to http://localhost:7860
```

---

## ğŸ“ Repository Structure

```
ai-demos/
â”œâ”€â”€ ğŸ“± app/                           # AI Compare application source
â”‚   â”œâ”€â”€ python-ollama-open-webui.py     # Main Gradio application
â”‚   â”œâ”€â”€ Dockerfile.suse                 # SUSE BCI-based container
â”‚   â”œâ”€â”€ Dockerfile.upstream             # Debian-based container
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â””â”€â”€ tests/                          # Application test suite
â”œâ”€â”€ ğŸ“¦ charts/                        # Production Helm charts
â”‚   â”œâ”€â”€ ai-compare/                     # Upstream community chart
â”‚   â””â”€â”€ ai-compare-suse/               # SUSE enterprise chart
â”œâ”€â”€ ğŸ“‹ Demo Guides/                   # Step-by-step demonstrations
â”‚   â”œâ”€â”€ demo-1.md                       # GPU infrastructure with Rancher
â”‚   â”œâ”€â”€ demo-2.md                       # Multi-method deployment
â”‚   â”œâ”€â”€ demo-3.md                       # SUSE Observability monitoring
â”‚   â”œâ”€â”€ demo-4.md                       # Container security with NeuVector
â”‚   â””â”€â”€ demo-5.md                       # Zero-trust network security
â”œâ”€â”€ ğŸš€ fleet/                         # GitOps deployment automation
â”‚   â”œâ”€â”€ fleet.yaml                      # Fleet configuration
â”‚   â””â”€â”€ gpu-operator/                   # GPU operator automation
â”œâ”€â”€ ğŸ”§ install/                       # Infrastructure setup guides
â”‚   â”œâ”€â”€ README.md                       # Installation overview
â”‚   â”œâ”€â”€ Install-GPU-Operator.md        # GPU infrastructure setup
â”‚   â”œâ”€â”€ Enable-SUSE-AI-Observability.md # Monitoring configuration
â”‚   â””â”€â”€ Install-NVIDIA-drivers.md      # Driver installation guide
â”œâ”€â”€ ğŸ”„ pipelines/                     # AI pipeline configurations
â”‚   â”œâ”€â”€ response_level_pipeline.py     # Educational response processing
â”‚   â””â”€â”€ pipeline_config.yaml           # Pipeline configuration
â”œâ”€â”€ ğŸ“Š docs/                          # Technical documentation
â”‚   â”œâ”€â”€ OPENTELEMETRY-INTEGRATION.md   # Observability setup
â”‚   â”œâ”€â”€ AUTOMATED-DEPLOYMENT.md        # CI/CD configuration
â”‚   â””â”€â”€ AI-MODEL-CACHING.md           # Model caching strategies
â”œâ”€â”€ ğŸ–¼ï¸ assets/                        # Screenshots and documentation images
â””â”€â”€ ğŸ”¨ scripts/                       # Automation and utility scripts
```

---

## ğŸ”§ Advanced Configuration

### **GPU Acceleration**
```yaml
ollama:
  gpu:
    enabled: true
  hardware:
    type: nvidia
```

### **Enterprise Observability**
```yaml
aiCompare:
  observability:
    enabled: true
    otlpEndpoint: "http://opentelemetry-collector.suse-observability.svc.cluster.local:4318"
    collectGpuStats: true
```

### **Security Integration**
```yaml
neuvector:
  enabled: true
  dlpPolicies: true
  securityDemos: true
```

### **Development Mode**
```yaml
aiCompare:
  devMode:
    enabled: true
    persistence:
      enabled: true
    gitRepo: "https://github.com/your-org/ai-demos.git"
```

---

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/new-demo`
3. **Make your changes**: Add new demos or improve existing ones
4. **Test thoroughly**: Ensure all demos work in both SUSE and upstream environments
5. **Submit a pull request**: Include clear description of changes

### **Development Environment**
```bash
# Setup local development
git clone https://github.com/your-org/ai-demos.git
cd ai-demos/app
pip install -r requirements.txt
python python-ollama-open-webui.py

# Run tests
pytest tests/
helm test my-release
```

---

## ğŸ“œ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **ğŸ“– Documentation**: Check the [docs/](./docs/) directory for detailed technical guides
- **ğŸ› ï¸ Installation Help**: Review [install/README.md](./install/README.md) for setup assistance
- **ğŸ› Issues**: Open an issue in this repository for bug reports or feature requests
- **ğŸ’¬ Discussions**: Use GitHub Discussions for questions and community support

---

**Powered by SUSE's Enterprise Cloud-Native AI Platform**

*Complete demonstrations of enterprise AI workloads from infrastructure provisioning to application security and observability.*