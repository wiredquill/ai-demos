apiVersion: v2
name: llm-comm-upstream
description: |
  SUSE AI Demo Showcase - A comprehensive demonstration of building, deploying, 
  and managing AI applications on SUSE's cloud-native platform.
  
  üöÄ COMPLETE AI STACK DEPLOYMENT:
  ‚Ä¢ Ollama: Local LLM inference server for running models like TinyLlama
  ‚Ä¢ Open WebUI: Modern web interface for LLM interactions  
  ‚Ä¢ LLM Chat: Custom aggregation app combining responses from multiple sources
  ‚Ä¢ Pipelines: Advanced AI processing capabilities
  
  üåê UPSTREAM EDITION FEATURES:
  ‚Ä¢ Built on standard Debian-based Python images with apt package manager
  ‚Ä¢ Open WebUI v0.6.9 (standard upstream release)
  ‚Ä¢ Pipelines from upstream development (main branch)
  ‚Ä¢ Uses standard open-source container images for maximum compatibility
  
  ‚ö° KEY CAPABILITIES:
  ‚Ä¢ GPU acceleration support with NVIDIA runtime
  ‚Ä¢ Persistent storage for models and data
  ‚Ä¢ NFS model caching for faster deployments
  ‚Ä¢ Comprehensive observability integration
  ‚Ä¢ Automated testing and monitoring
type: application
version: 0.1.130
appVersion: "1.0.0"
